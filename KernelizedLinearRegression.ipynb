{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3f759d",
   "metadata": {},
   "source": [
    "A Gaussian kernel is given by: $$ \\langle x^{(i)}, x^{(j)} \\rangle = exp(\\frac{|| x_i - x_j ||^2}{-\\gamma})  $$\n",
    "\n",
    "Since x is one dimensional $$ \\langle x^{(i)}, x^{(j)} \\rangle = exp(\\frac{( x_i - x_j)^2}{-\\gamma})  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feda464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_function(x, z):\n",
    "    gamma = 100\n",
    "    return np.exp(- ((x - z) ** 2 / gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f9428",
   "metadata": {},
   "source": [
    "To make computation shorter, a matrix containing $ \\langle x^{(i)}, x^{(j)} \\rangle $ for each $ x_i , x_j $ in the training set can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kernel_matrix(x):\n",
    "    # generate m x m kernel matrix\n",
    "    n = x.shape[0]\n",
    "    k = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            k[i, j] = kernel_function(x[i, :], x[j, :])\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6fca1",
   "metadata": {},
   "source": [
    "Main function train() that fits the regression line and plots it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, learning_rate, steps):\n",
    "    beta = np.zeros((x.shape[0], 1))\n",
    "    kernel_matrix = generate_kernel_matrix(x)\n",
    "    labels = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a7db0",
   "metadata": {},
   "source": [
    "For 'normal' linear regression update rule would be : \n",
    "$$ \\Theta \\ += \\alpha \\sum_{i=1}^{n} (y^{(i)} - \\Theta^T x^{(i)})  \\ x $$\n",
    "or \n",
    "$$ \\Theta  \\ += \\alpha \\sum_{i=1}^{n} (y^{(i)} - \\Theta^T \\phi(x^{(i)}))  \\ \\phi(x) $$\n",
    "where $\\phi(x)$ is a feature mapping\n",
    "\n",
    "A kernel $ \\langle x, z \\rangle $ is defined as $ \\phi(x)^T \\phi(z) $\n",
    "\n",
    "And the assumption is that :\n",
    "$$ \\Theta = \\sum_{i=1}^{n} \\beta _i \\phi(x^{(i)}) $$\n",
    "\n",
    "Then hypothesis can be rewritten as\n",
    "\n",
    "$$ \\Theta^T \\phi(x) = \\sum_{i=1}^{n} \\beta _i \\phi(x^{(i)})^T \\phi(x) = \\sum_{i=1}^{n} \\beta _i \\langle x^{(i)}, x \\rangle$$\n",
    "\n",
    "So if we take $ \\beta $ as parameters instead of $ \\Theta $ update rule can be rewritten as:\n",
    "$$ \\beta_j \\ += \\alpha (y^{(j)} - \\sum_{i=1}^{n} \\beta _i \\langle x^{(j)}, x^{(i)} \\rangle ) $$\n",
    "\n",
    "Or with usage of kernel matrix K (defined above)\n",
    "\n",
    "$$\\beta \\ +=  \\ \\alpha (y - K\\beta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(steps):\n",
    "        beta += learning_rate * (labels - kernel_matrix.dot(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15e37f",
   "metadata": {},
   "source": [
    "plotting part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae22d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mscatter(x, y)\n\u001b[0;32m      3\u001b[0m axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n\u001b[0;32m      4\u001b[0m (x_min, x_max) \u001b[38;5;241m=\u001b[39m axes\u001b[38;5;241m.\u001b[39mget_xlim()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "    plt.scatter(x, y)\n",
    "\n",
    "    axes = plt.gca()\n",
    "    (x_min, x_max) = axes.get_xlim()\n",
    "\n",
    "    y_a = np.empty(0)\n",
    "    x_a = range(int(x_min), int(x_max))\n",
    "    # Theta.transpose * feature_mapping(x) = sum beta_i * K(x_i, x)\n",
    "    for i in x_a:\n",
    "        s = 0\n",
    "        for j in range(x.shape[0]):\n",
    "            s += beta[j] * kernel_function(x[j], i)\n",
    "        y_a = np.append(y_a, s)\n",
    "\n",
    "    # plot approximated resulting curve as straight lines between segments\n",
    "    for i in range(len(y_a) - 1):\n",
    "        plt.plot([x_a[i], x_a[i]+1], [y_a[i], y_a[i+1]], color='r')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43b7fe",
   "metadata": {},
   "source": [
    "![plot](plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae12a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
